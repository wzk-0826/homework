{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "\n",
    "\n",
    "# Regression-Master Template\n",
    "\n",
    "\n",
    "Template for regression and time series based predictive modelling including the model development steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Problem Statement](#0)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#1)\n",
    "    * [2.1. Load Libraries](#1.1)    \n",
    "    * [2.2. Load Dataset](#1.2)\n",
    "* [3. Exploratory Data Analysis](#2)\n",
    "    * [3.1 Descriptive Statistics](#2.1)    \n",
    "    * [3.2. Data Visualisation](#2.2)\n",
    "* [4. Data Preparation](#3)\n",
    "    * [4.1 Data Cleaning](#3.1)\n",
    "    * [4.3.Feature Selection](#3.2)\n",
    "    * [4.3.Data Transformation](#3.3) \n",
    "        * [4.3.1 Rescaling ](#3.3.1)\n",
    "        * [4.3.2 Standardization](#3.3.2)\n",
    "        * [4.3.3 Normalization](#3.3.3)    \n",
    "* [5.Evaluate Algorithms and Models](#4)        \n",
    "    * [5.1. Train/Test Split](#4.1)\n",
    "    * [5.2. Test Options and Evaluation Metrics](#4.2)\n",
    "    * [5.3. Compare Models and Algorithms](#4.3)\n",
    "        * [5.3.1 Common Regression Models](#4.3.1)\n",
    "        * [5.3.2 Ensemble Models](#4.3.2)\n",
    "        * [5.3.3 Deep Learning Models](#4.3.3)  \n",
    "    * [5.4. Time Series based Models-ARIMA and LSTM](#4.4)\n",
    "        * [5.4.1 ARIMA Model](#4.4.1)\n",
    "        * [5.4.2 LSTM Model](#4.4.2) \n",
    "* [6. Model Tuning and Grid Search](#5)\n",
    "    * [6.1 Common Regression, Ensemble and DeepNNRegressor Grid Search](#5.1)\n",
    "    * [6.2 ARIMA and LSTM Grid Search](#5.2) \n",
    "* [7. Finalize the Model](#6)  \n",
    "    * [7.1. Results on test dataset](#6.1)\n",
    "    * [7.1. Variable Intuition/Feature Selection](#6.2) \n",
    "    * [7.3. Save model for later use](#6.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this jupyter notebook is to under the following. A sample problem of stock price prediction in presented in this case study.\n",
    "- How to work through a predictive modeling problem end-to-end. This notebook is applicable both for regression and classification problems.\n",
    "- How to use data transforms to improve model performance.\n",
    "- How to use algorithm tuning to improve model performance.\n",
    "- How to use ensemble methods and tuning of ensemble methods to improve model performance.\n",
    "- How to use deep Learning methods.\n",
    "- Following Models are implemented\n",
    "\n",
    "    * Linear Regression\n",
    "    * Lasso\n",
    "    * Elastic Net \n",
    "    * KNN\n",
    "    * Decision Tree (CART)\n",
    "    * Support Vector Machine \n",
    "    * Ada Boost\n",
    "    * Gradient Boosting Method\n",
    "    * Random Forest\n",
    "    * Extra Trees\n",
    "    * Neural Network - Shallow - Using sklearn\n",
    "    * Deep Neural Network - Using Keras\n",
    "- Time Series Models\n",
    "    * ARIMA Model\n",
    "    * LSTM - Using Keras\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 2. Getting Started- Loading the data and python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SGD\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#Libraries for Statistical Models\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msm\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519"
   },
   "outputs": [],
   "source": [
    "# Get the data by webscapping using pandas datareader\n",
    "return_period = 21\n",
    "\n",
    "\n",
    "stk_tickers = ['MSFT', 'IBM', 'GOOGL']\n",
    "ccy_tickers = ['DEXJPUS', 'DEXUSUK']\n",
    "idx_tickers = ['SP500', 'DJIA', 'VIXCLS']\n",
    "\n",
    "stk_data = web.DataReader(stk_tickers, 'yahoo')\n",
    "ccy_data = web.DataReader(ccy_tickers, 'fred')\n",
    "idx_data = web.DataReader(idx_tickers, 'fred')\n",
    "\n",
    "Y = np.log(stk_data.loc[:, ('Adj Close', 'MSFT')]).diff(return_period).shift(-return_period)\n",
    "Y.name = Y.name[-1]+'_pred'\n",
    "\n",
    "X1 = np.log(stk_data.loc[:, ('Adj Close', ('GOOGL', 'IBM'))]).diff(return_period)\n",
    "X1.columns = X1.columns.droplevel()\n",
    "X2 = np.log(ccy_data).diff(return_period)\n",
    "X3 = np.log(idx_data).diff(return_period)\n",
    "\n",
    "X4 = pd.concat([Y.diff(i) for i in [21, 63, 126,252]], axis=1).dropna()\n",
    "X4.columns = ['1M', '3M', '6M', '1Y']\n",
    "\n",
    "X = pd.concat([X1, X2, X3, X4], axis=1)\n",
    "\n",
    "dataset = pd.concat([Y, X], axis=1).dropna()\n",
    "Y = dataset.loc[:, Y.name]\n",
    "X = dataset.loc[:, X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the data to supervised regression format\n",
    "All the predictor variables are changed to lagged variable, as the t-1 value of the lagged variable will be used for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, lag=1):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)    \n",
    "    cols, names = list(), list()\n",
    "    for i in range(lag, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg = pd.DataFrame(data.iloc[:,0]).join(agg)\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= series_to_supervised(dataset,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "df6a4523-b385-69ee-c933-592826d81431"
   },
   "source": [
    "<a id='2'></a>\n",
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 3.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52f85dc2-0f91-3c50-400e-ddc38bea966b"
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at data\n",
    "pd.set_option('display.width', 100)\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f36dd804-0c16-f0c9-05c9-d22b85a79e75"
   },
   "outputs": [],
   "source": [
    "# types\n",
    "pd.set_option('display.max_rows', 500)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7bffeec0-5bbc-fffb-18f2-3da56b862ca3"
   },
   "outputs": [],
   "source": [
    "# describe data\n",
    "pd.set_option('precision', 3)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 3.2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16d50177-f93e-9d26-af7a-313d7ebe9fcf"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca420570-fce1-e2ff-8511-50691e099d69"
   },
   "outputs": [],
   "source": [
    "# density\n",
    "dataset.plot(kind='density', subplots=True, layout=(4,4), sharex=False, legend=True, fontsize=1, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box and Whisker Plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = dataset.corr()\n",
    "pyplot.figure(figsize=(15,15))\n",
    "pyplot.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot Matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "pyplot.figure(figsize=(15,15))\n",
    "scatter_matrix(dataset,figsize=(12,12))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "## 3.3. Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series broken down into different time series comonent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= dataset[\"MSFT_pred\"]\n",
    "res = sm.tsa.seasonal_decompose(Y,freq=365)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 4.1. Data Cleaning\n",
    "Check for the NAs in the rows, either drop them or fill them with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are null values drop the rown contianing the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows containing NA\n",
    "#dataset.dropna(axis=0)\n",
    "# Fill na with 0\n",
    "#dataset.fillna('0')\n",
    "\n",
    "#Filling the NAs with the mean of the column.\n",
    "#dataset['col'] = dataset['col'].fillna(dataset['col'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 4.3. Feature Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "The example below uses the chi-squared (chi²) statistical test for non-negative features to select 10 of the best features from the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "bestfeatures = SelectKBest(k=5)\n",
    "bestfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= dataset[\"MSFT_pred\"]\n",
    "X = dataset.loc[:, dataset.columns != 'MSFT_pred']\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen from the result above that t-1 is an important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 4.4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.1'></a>\n",
    "### 4.4.1. Rescale Data\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms\n",
    "can benefit from rescaling the attributes to all have the same scale. Often this is referred to\n",
    "as normalization and attributes are often rescaled into the range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "rescaledX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.2'></a>\n",
    "### 4.4.2. Standardize Data\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and\n",
    "differing means and standard deviations to a standard Gaussian distribution with a mean of\n",
    "0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "StandardisedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "StandardisedX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.3'></a>\n",
    "### 4.4.1. Normalize Data\n",
    "Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called\n",
    "a unit norm or a vector with the length of 1 in linear algebra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(X)\n",
    "NormalizedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "NormalizedX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 5. Evaluate Algorithms and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "\n",
    "validation_size = 0.2\n",
    "\n",
    "#In case the data is not dependent on the time series, then train and test split randomly\n",
    "seed = 7\n",
    "# X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "#In case the data is not dependent on the time series, then train and test split should be done based on sequential sample\n",
    "#This can be done by selecting an arbitrary split point in the ordered list of observations and creating two new datasets.\n",
    "\n",
    "train_size = int(len(X) * (1-validation_size))\n",
    "X_train, X_validation = X[0:train_size], X[train_size:len(X)]\n",
    "Y_train, Y_validation = Y[0:train_size], Y[train_size:len(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2. Test Options and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5702bc31-06bf-8b6a-42de-366a6b3311a8"
   },
   "outputs": [],
   "source": [
    "# test options for regression\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "#scoring ='neg_mean_absolute_error'\n",
    "#scoring = 'r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3. Compare Models and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.1'></a>\n",
    "### 5.3.1. Common Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "772802f7-f4e4-84ee-6377-6464ab2e5da4"
   },
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "#Neural Network\n",
    "models.append(('MLP', MLPRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.2'></a>\n",
    "### 5.3.2. Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensable Models \n",
    "# Boosting methods\n",
    "models.append(('ABR', AdaBoostRegressor()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    "# Bagging methods\n",
    "models.append(('RFR', RandomForestRegressor()))\n",
    "models.append(('ETR', ExtraTreesRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.3'></a>\n",
    "### 5.3.3. Deep Learning Model-NN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running deep learning models and performing cross validation takes time\n",
    "#Set the following Flag to 0 if the Deep LEarning Models Flag has to be disabled\n",
    "EnableDeepLearningRegreesorFlag = 0\n",
    "\n",
    "def create_model(neurons=12, activation='relu', learn_rate = 0.01, momentum=0):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=X_train.shape[1], activation=activation))\n",
    "        #The number of hidden layers can be increased\n",
    "        model.add(Dense(2, activation=activation))\n",
    "        # Final output layer\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model\n",
    "        optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Deep Learning Regressor\n",
    "if ( EnableDeepLearningRegreesorFlag == 1):\n",
    "    models.append(('DNN', KerasRegressor(build_fn=create_model, epochs=100, batch_size=100, verbose=1)))       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a784ab4a-eb59-98cc-76cf-b55f382d057a"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    #converted mean square error to positive. The lower the beter\n",
    "    cv_results = -1* cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "67873e9d-bc9b-6963-f594-805f1efbfbb3"
   },
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart shows MSE. Lower the MSE, better is the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.4'></a>\n",
    "## 5.4. Time Series based Models- ARIMA and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.4.1'></a>\n",
    "### 5.4.1 Time Series Model - ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data for the ARIMAX Model, seperating endogeneous and exogenous variables\n",
    "X_train_ARIMA=X_train.drop(['MSFT_pred(t-1)'], axis = 'columns' ).dropna()\n",
    "X_validation_ARIMA=X_validation.drop(['MSFT_pred(t-1)'], axis = 'columns' ).dropna()\n",
    "tr_len = len(X_train_ARIMA)\n",
    "te_len = len(X_validation_ARIMA)\n",
    "to_len = len (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "modelARIMA=ARIMA(endog=Y_train,exog=X_train_ARIMA,order=[1,0,0])\n",
    "#modelARIMA= SARIMAX(Y_train,order=(1,1,0),seasonal_order=[1,0,0,0],exog = X_train_ARIMA)\n",
    "\n",
    "model_fit = modelARIMA.fit()\n",
    "#print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Training_ARIMA = mean_squared_error(Y_train, model_fit.fittedvalues)\n",
    "predicted = model_fit.predict(start = tr_len -1 ,end = to_len -1, exog = X_validation_ARIMA)[1:]\n",
    "error_Test_ARIMA = mean_squared_error(Y_validation,predicted)\n",
    "error_Test_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Cross validation if possible\n",
    "# #model = build_model(_alpha=1.0, _l1_ratio=0.3)\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# scores = cross_val_score(modelARIMA, X_train, Y_train, cv=tscv, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.4.2'></a>\n",
    "### 5.4.2 LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be in 3D format for the LSTM model. So, Performing the data transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LSTM, X_validation_LSTM = np.array(X_train), np.array(X_validation)\n",
    "Y_train_LSTM, Y_validation_LSTM = np.array(Y_train), np.array(Y_validation)\n",
    "X_train_LSTM= X_train_LSTM.reshape((X_train_LSTM.shape[0], 1, X_train_LSTM.shape[1]))\n",
    "X_validation_LSTM= X_validation_LSTM.reshape((X_validation_LSTM.shape[0], 1, X_validation_LSTM.shape[1]))\n",
    "print(X_train_LSTM.shape, Y_train_LSTM.shape, X_validation_LSTM.shape, Y_validation_LSTM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def create_LSTMmodel(neurons=12, learn_rate = 0.01, momentum=0):\n",
    "        # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(X_train_LSTM.shape[1], X_train_LSTM.shape[2])))\n",
    "    #More number of cells can be added if needed \n",
    "    model.add(Dense(1))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "LSTMModel = create_LSTMmodel(12, learn_rate = 0.01, momentum=0)\n",
    "LSTMModel_fit = LSTMModel.fit(X_train_LSTM, Y_train_LSTM, validation_data=(X_validation_LSTM, Y_validation_LSTM),epochs=50, batch_size=72, verbose=0, shuffle=False)# plot history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual plot to check if the error is reducing\n",
    "pyplot.plot(LSTMModel_fit.history['loss'], label='train')\n",
    "pyplot.plot(LSTMModel_fit.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Training_LSTM = mean_squared_error(Y_train_LSTM, LSTMModel.predict(X_train_LSTM))\n",
    "predicted = LSTMModel.predict(X_validation_LSTM)\n",
    "error_Test_LSTM = mean_squared_error(Y_validation,predicted)\n",
    "error_Test_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Comparison of all the algorithms ( including Time Series Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "results.append(error_Test_ARIMA)\n",
    "results.append(error_Test_LSTM)\n",
    "names.append(\"ARIMA\")\n",
    "names.append(\"LSTM\")\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison-Post Time Series')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search uses Cross validation which isn't appropriate for the time series models such as LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 6. Model Tuning and Grid Search\n",
    "This section shown the Grid search for all the Machine Learning and time series models mentioned in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1'></a>\n",
    "### 6.1. Common Regression, Ensemble and DeepNNRegressor Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Grid search : LinearRegression\n",
    "'''\n",
    "fit_intercept : boolean, optional, default True\n",
    "    whether to calculate the intercept for this model. If set\n",
    "    to False, no intercept will be used in calculations\n",
    "    (e.g. data is expected to be already centered).\n",
    "'''\n",
    "param_grid = {'fit_intercept': [True, False]}\n",
    "model = LinearRegression()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Grid search : Lasso\n",
    "'''\n",
    "alpha : float, optional\n",
    "    Constant that multiplies the L1 term. Defaults to 1.0.\n",
    "    ``alpha = 0`` is equivalent to an ordinary least square, solved\n",
    "    by the :class:`LinearRegression` object. For numerical\n",
    "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
    "    Given this, you should use the :class:`LinearRegression` object.\n",
    "''' \n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.7, 1, 1.5, 3, 5]}\n",
    "model = Lasso()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Grid Search : ElasticNet\n",
    "'''\n",
    "alpha : float, optional\n",
    "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
    "    See the notes for the exact mathematical meaning of this\n",
    "    parameter.``alpha = 0`` is equivalent to an ordinary least square,\n",
    "    solved by the :class:`LinearRegression` object. For numerical\n",
    "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
    "    Given this, you should use the :class:`LinearRegression` object.\n",
    "\n",
    "l1_ratio : float\n",
    "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
    "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
    "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
    "    combination of L1 and L2.\n",
    "'''\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.3, 0.7, 1, 1.5, 3, 5],\n",
    "              'l1_ratio': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 0.99]}\n",
    "model = ElasticNet()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Grid search : KNeighborsRegressor \n",
    "'''\n",
    "n_neighbors : int, optional (default = 5)\n",
    "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "'''\n",
    "param_grid = {'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21]}\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Grid search : DecisionTreeRegressor \n",
    "'''\n",
    "min_samples_split : int, float, optional (default=2)\n",
    "    The minimum number of samples required to split an internal node:\n",
    "\n",
    "    - If int, then consider `min_samples_split` as the minimum number.\n",
    "    - If float, then `min_samples_split` is a percentage and\n",
    "      `ceil(min_samples_split * n_samples)` are the minimum\n",
    "      number of samples for each split.\n",
    "'''\n",
    "param_grid={'min_samples_split': [2,3,4,5,6,7,8,9,10]}\n",
    "model = DecisionTreeRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Grid search : SVR \n",
    "'''\n",
    "C : float, optional (default=1.0)\n",
    "    Penalty parameter C of the error term.\n",
    "\n",
    "epsilon : float, optional (default=0.1)\n",
    "     Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
    "     within which no penalty is associated in the training loss function\n",
    "     with points predicted within a distance epsilon from the actual\n",
    "     value.\n",
    "gamma : float, optional (default='auto')\n",
    "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "    If gamma is 'auto' then 1/n_features will be used instead.\n",
    "'''\n",
    "param_grid={'C': [0.01, 0.03,0.1,0.3,1,3,10,30,100],\n",
    "            'gamma': [0.001, 0.01, 0.1, 1]},\n",
    "            #'epslion': [0.01, 0.1, 1]}\n",
    "model = SVR()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Grid search : MLPRegressor \n",
    "'''\n",
    "hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "    The ith element represents the number of neurons in the ith\n",
    "    hidden layer.\n",
    "'''\n",
    "param_grid={'hidden_layer_sizes': [(20,), (50,), (20,20), (20, 30, 20)]}\n",
    "model = MLPRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Grid search : RandomForestRegressor \n",
    "'''\n",
    "n_estimators : integer, optional (default=10)\n",
    "    The number of trees in the forest.\n",
    "'''\n",
    "param_grid = {'n_estimators': [50,100,150,200,250,300,350,400]}\n",
    "model = RandomForestRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Grid search : GradientBoostingRegressor \n",
    "'''\n",
    "n_estimators:\n",
    "\n",
    "    The number of boosting stages to perform. Gradient boosting\n",
    "    is fairly robust to over-fitting so a large number usually\n",
    "    results in better performance.\n",
    "''' \n",
    "param_grid = {'n_estimators': [50,100,150,200,250,300,350,400]}\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Grid search : ExtraTreesRegressor \n",
    "'''\n",
    "n_estimators : integer, optional (default=10)\n",
    "    The number of trees in the forest.\n",
    "''' \n",
    "param_grid = {'n_estimators': [50,100,150,200,250,300,350,400]}\n",
    "model = ExtraTreesRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Grid search : AdaBoostRegre\n",
    "'''\n",
    "n_estimators : integer, optional (default=50)\n",
    "    The maximum number of estimators at which boosting is terminated.\n",
    "    In case of perfect fit, the learning procedure is stopped early.\n",
    "\n",
    "learning_rate : float, optional (default=1.)\n",
    "    Learning rate shrinks the contribution of each regressor by\n",
    "    ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
    "    ``n_estimators``.\n",
    "''' \n",
    "param_grid = {'n_estimators': [50,100,150,200,250,300,350,400],\n",
    "             'learning_rate': [1, 2, 3]}\n",
    "model = AdaBoostRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Grid search : KerasNNRegressor \n",
    "'''\n",
    "nn_shape : tuple, length = n_layers - 2, default (100,)\n",
    "    The ith element represents the number of neurons in the ith\n",
    "    hidden layer.\n",
    "''' \n",
    "#Add Deep Learning Regressor\n",
    "if ( EnableDeepLearningRegreesorFlag == 1):\n",
    "    param_grid={'nn_shape': [(20,), (50,), (20,20), (20, 30, 20)]}\n",
    "    model = KerasNNRegressor()\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.2'></a>\n",
    "### 6.2. Grid Search- Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for ARIMA Model\n",
    "#Change p,d and q and check for the best result\n",
    "\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "#Assuming that the train and Test Data is already defined before\n",
    "def evaluate_arima_model(arima_order):\n",
    "    #predicted = list()     \n",
    "    modelARIMA=ARIMA(endog=Y_train,exog=X_train_ARIMA,order=arima_order)\n",
    "    model_fit = modelARIMA.fit()   \n",
    "    #error on the test set\n",
    "#     tr_len = len(X_train_ARIMA)\n",
    "#     to_len = len(X_train_ARIMA) + len(X_validation_ARIMA)\n",
    "#     predicted = model_fit.predict(start = tr_len -1 ,end = to_len -1, exog = X_validation_ARIMA)[1:]\n",
    "#     error = mean_squared_error(predicted, Y_validation)\n",
    "    # error on the training set \n",
    "    error = mean_squared_error(Y_train, model_fit.fittedvalues)\n",
    "    return error\n",
    " \n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(p_values, d_values, q_values): \n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)                \n",
    "                try:\n",
    "                    mse = evaluate_arima_model(order)                    \n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.7f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.7f' % (best_cfg, best_score))\n",
    "    \n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2]\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 2)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(p_values, d_values, q_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for LSTM Model\n",
    "\n",
    "# evaluate an LSTM model for a given order (p,d,q)\n",
    "def evaluate_LSTM_model(neurons=12, learn_rate = 0.01, momentum=0):\n",
    "    #predicted = list()     \n",
    "    LSTMModel = create_LSTMmodel(neurons, learn_rate, momentum)\n",
    "    LSTMModel_fit = LSTMModel.fit(X_train_LSTM, Y_train_LSTM,epochs=50, batch_size=72, verbose=0, shuffle=False)\n",
    "    predicted = LSTMModel.predict(X_validation_LSTM)\n",
    "    error = mean_squared_error(predicted, Y_validation)\n",
    "    return error\n",
    "\n",
    "# evaluate combinations of different variables of LSTM Model\n",
    "def evaluate_combinations_LSTM(neurons, learn_rate, momentum): \n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for n in neurons:\n",
    "        for l in learn_rate:\n",
    "            for m in momentum:\n",
    "                combination = (n,l,m)                \n",
    "                try:\n",
    "                    mse = evaluate_LSTM_model(n,l,m)                    \n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, combination\n",
    "                    print('LSTM%s MSE=%.7f' % (combination,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best LSTM%s MSE=%.7f' % (best_cfg, best_score))\n",
    "    \n",
    "# evaluate parameters\n",
    "neurons = [1, 5]\n",
    "learn_rate = [0.001, 0.3]\n",
    "momentum = [0.0, 0.9]\n",
    "#Other Parameters can be modified as well\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_combinations_LSTM(neurons,learn_rate,momentum)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 7. Finalise the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select one of the model to finalize the data. Looking at the results for the Random Forest Model. Looking at the results for the RandomForestRegressor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1. Results on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "#rescaledX = scaler.transform(X_train)\n",
    "model = RandomForestRegressor(n_estimators=250) # rbf is default kernel\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9725666-3c21-69d1-ddf6-45e47d982444"
   },
   "outputs": [],
   "source": [
    "# estimate accuracy on validation set\n",
    "# transform the validation dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "#rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation, predictions))\n",
    "print(r2_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2. Variable Intuition/Feature Importance\n",
    "Let us look into the Feature Importance of the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based regressors\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3. Save Model for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "# estimate accuracy on validation set\n",
    "#rescaledValidationX = scaler.transform(X_validation) #in case the data is scaled.\n",
    "#predictions = model.predict(rescaledValidationX)\n",
    "predictions = model.predict(X_validation)\n",
    "result = mean_squared_error(Y_validation, predictions)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "new_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
